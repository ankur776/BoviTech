# -*- coding: utf-8 -*-
"""Copy of model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1azTHbD3_8l9tBk3vsv9Q70REp-IpitRF
"""

#!/bin/bash
!curl -L -o ~/cows-and-buffalo-computer-vision-dataset.zip\
  https://www.kaggle.com/api/v1/datasets/download/raghavdharwal/cows-and-buffalo-computer-vision-dataset
!unzip ~/cows-and-buffalo-computer-vision-dataset.zip -d ~/cows-and-buffalo-computer-vision-dataset

!pip install tensorflow

import tensorflow as tf

"""# Task
Import necessary libraries for training an image-based model.

## Import libraries

### Subtask:
Import necessary libraries for training an image-based model.

**Reasoning**:
Import pandas, numpy, os, and tensorflow to prepare for training an image-based model.
"""

import pandas as pd
import numpy as np
import os
import tensorflow as tf

"""## Load and preprocess data

### Subtask:
Load the images and their corresponding labels, and preprocess them for model training (e.g., resizing, normalization).

**Reasoning**:
Define the paths to the training and validation image directories and create image data generators for both training and validation sets using TensorFlow's `ImageDataGenerator`.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths to the training and validation directories
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')
validation_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/valid')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Create ImageDataGenerator for validation (only resizing and normalization)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Use flow_from_directory to load images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

"""**Reasoning**:
The previous command failed because the validation directory '/root/cows-and-buffalo-computer-vision-dataset/valid' was not found. Inspect the extracted directory to find the correct path for the validation set.


"""

!ls -R ~/cows-and-buffalo-computer-vision-dataset

"""**Reasoning**:
The `ls` command shows that there is no 'valid' directory, only a 'train' directory. It seems the dataset only contains a training set. I will modify the code to only use the training data for training and validation by splitting it.


"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

"""## Define the model

### Subtask:
Choose and define an appropriate model architecture for image classification.

**Reasoning**:
Import necessary layers and models from tensorflow.keras.applications and tensorflow.keras.models, load a pre-trained base model, freeze its layers, add pooling and dense layers, and print the model summary.
"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

!pip install streamlit

"""After installing streamlit, you can run your streamlit application using the following command:

## Compile and train the model

### Subtask:
Compile the model with an optimizer and loss function, and then train it on the preprocessed data.

**Reasoning**:
Compile the model with the specified optimizer, loss function, and metrics, and then train the model using the training and validation generators.
"""

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

"""## Evaluate the model

### Subtask:
Evaluate the trained model on a separate test set to assess its performance.

**Reasoning**:
Define the path to the test directory, create an ImageDataGenerator for the test set without augmentation, and load the test images using flow_from_directory.
"""

# Define the path to the test directory
test_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/test')

# Create ImageDataGenerator for the test set (only rescaling)
test_datagen = ImageDataGenerator(rescale=1./255)

# Use flow_from_directory to load images from the test directory
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False  # Set shuffle to False for evaluation
)

"""**Reasoning**:
The previous attempt failed because the test directory does not exist. I need to check the available directories again to find the correct path for the test set. Based on the previous output, it seems there is no separate 'test' directory. I will check the available directories in the dataset again.


"""

!ls -R ~/cows-and-buffalo-computer-vision-dataset

"""## Evaluate the model

### Subtask:
Retry evaluating the trained model. Since there is no separate test set, evaluate the model using the validation set instead.

**Reasoning**:
Evaluate the trained model using the validation generator and print the results.
"""

# Evaluate the model on the validation set
loss, accuracy = model.evaluate(validation_generator, steps=validation_steps)

# Print the evaluation results
print(f"Validation Loss: {loss:.4f}")
print(f"Validation Accuracy: {accuracy:.4f}")

"""## Summary:

### Data Analysis Key Findings

*   The necessary libraries (`pandas`, `numpy`, `os`, and `tensorflow`) were successfully imported.
*   The dataset only contained a `train` directory, so the `ImageDataGenerator` was used with a `validation_split` of 0.2 to create training and validation sets from this single directory.
*   A transfer learning model based on a pre-trained MobileNetV2 model was defined, with the base layers frozen and new pooling and dense layers added for classification.
*   The model was compiled using the Adam optimizer and categorical cross-entropy loss, achieving 100% training and validation accuracy after the first epoch.
*   Due to the absence of a dedicated test set, the model was evaluated on the validation set, yielding a loss of 0.0000 and an accuracy of 1.0000.

### Insights or Next Steps

*   The very high accuracy achieved quickly on both the training and validation sets suggests the dataset might be too simple or there could be data leakage. Further investigation into the dataset and potential augmentation strategies is recommended.
*   To get a more reliable assessment of the model's performance, collecting or generating a separate, unseen test set would be beneficial.

# Task
Help me train an image-based model and run a Streamlit application.

## Evaluate the model

### Subtask:
Retry evaluating the trained model. Since there is no separate test set, evaluate the model using the validation set instead.

**Reasoning**:
Evaluate the trained model using the validation generator and print the results.
"""

# Evaluate the model on the validation set
loss, accuracy = model.evaluate(validation_generator, steps=validation_steps)

# Print the evaluation results
print(f"Validation Loss: {loss:.4f}")
print(f"Validation Accuracy: {accuracy:.4f}")

import joblib

# Save the model using joblib
joblib.dump(model, 'image_classification_model.joblib')

#!/bin/bash
!curl -L -o ~/cows-and-buffalo-computer-vision-dataset.zip\
  https://www.kaggle.com/api/v1/datasets/download/raghavdharwal/cows-and-buffalo-computer-vision-dataset
!unzip ~/cows-and-buffalo-computer-vision-dataset.zip -d ~/cows-and-buffalo-computer-vision-dataset

import pandas as pd
import numpy as np
import os
import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

import joblib

# Save the model using joblib
joblib.dump(model, 'image_classification_model.joblib')

import pandas as pd
import numpy as np
import os
import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

import joblib

# Save the model using joblib
joblib.dump(model, 'image_classification_model.joblib')

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

import joblib

# Save the model using joblib
joblib.dump(model, 'image_classification_model.joblib')

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

# Save trained model in native Keras format
model.save("cow_buffalo_model.keras")

# Save class names
import json
with open("class_names.json", "w") as f:
    json.dump(train_generator.class_indices, f)

print("✅ Model and class names saved successfully!")

import joblib

# Save the model using joblib
joblib.dump(model, 'image_classification_model.joblib')

"""## Summary:

### Data Analysis Key Findings

* The model achieved a validation loss of approximately 0.0000.
* The model achieved a validation accuracy of 1.0000.

### Insights or Next Steps

* The model performed exceptionally well on the validation set, suggesting it has learned to classify the images accurately. However, this high performance on the validation set could potentially indicate overfitting.
* Evaluate the model on a separate, unseen test dataset to get a more reliable measure of its generalization performance.

"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import tensorflow as tf
# from PIL import Image
# import numpy as np
# # Removed joblib import
# # import joblib
# 
# # Load the trained model in Keras format
# model = tf.keras.models.load_model('cow_buffalo_model.keras')
# 
# # Load the class names from the JSON file
# import json
# with open("class_names.json", "r") as f:
#     class_indices = json.load(f)
#     # Reverse the dictionary to get class names from indices
#     class_names = {v: k for k, v in class_indices.items()}
# 
# 
# st.title('Cows and Buffalo Classification')
# 
# uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"]) # Added more image types
# 
# if uploaded_file is not None:
#     # Read the image
#     image = Image.open(uploaded_file)
#     st.image(image, caption='Uploaded Image.', use_column_width=True)
# 
#     # Preprocess the image
#     img = image.resize((224, 224))
#     img_array = np.array(img)
#     img_array = np.expand_dims(img_array, axis=0)
#     img_array = img_array / 255.0  # Rescale the same way as training data
# 
#     # Make prediction
#     predictions = model.predict(img_array)
#     score = tf.nn.softmax(predictions[0])
# 
#     st.write(f"This image most likely belongs to {class_names[np.argmax(score)]} with a {100 * np.max(score):.2f}% confidence.")

"""## Configure Git

### Subtask:
Set up your Git username and email.

**Reasoning**:
Configure the local Git environment with your username and email. This information will be associated with your commits.
"""

!git config --global user.name "ankur776"
!git config --global user.email "saxenaankur0376@gmail.com"

"""## Add remote repository

### Subtask:
Add your GitHub repository as a remote origin.

**Reasoning**:
Add the URL of your GitHub repository as a remote origin named 'origin'. This links your local repository to the remote one. Replace `YOUR_USERNAME` and `YOUR_REPOSITORY_NAME` with your actual GitHub username and repository name.
"""

!git remote add origin https://github.com/ankur776/BoviTech.git

"""## Push to GitHub (Retry)

### Subtask:
Attempt to push the committed model file to your GitHub repository again.

**Reasoning**:
Retry pushing the committed changes to your remote GitHub repository after re-configuring the authentication and confirming the remote origin exists.
"""

!git push -u origin master

"""## Authenticate with GitHub (Retry)

### Subtask:
Ensure proper authentication with your GitHub account.

**Reasoning**:
The previous push failed due to authentication issues. This step re-configures the credential helper to store your GitHub Personal Access Token securely. **Make sure to replace `YOUR_PAT` with your actual token.**
"""

# Replace YOUR_PAT with your actual Personal Access Token
!git config --global credential.helper 'store --file /root/.git-credentials'
!echo "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" >> /root/.git-credentials

"""## Push to GitHub (Retry)

### Subtask:
Attempt to push the committed model file to your GitHub repository again.

**Reasoning**:
Retry pushing the committed changes to your remote GitHub repository.
"""

!git push -u origin master

"""## Push to GitHub (Retry)

### Subtask:
Attempt to push the committed model file to your GitHub repository again.

**Reasoning**:
Retry pushing the committed changes to your remote GitHub repository after re-configuring the authentication.
"""

!git push -u origin master

"""## Push to GitHub (Retry)

### Subtask:
Attempt to push the committed model file to your GitHub repository again.

**Reasoning**:
Retry pushing the committed changes to your remote GitHub repository after re-configuring the authentication.
"""

!git push -u origin master

"""## Push to GitHub

### Subtask:
Push the committed model file to your GitHub repository.

**Reasoning**:
Push the committed changes from your local 'master' branch to the 'main' branch of your remote GitHub repository. If your default branch is named something else (e.g., 'main'), adjust the command accordingly.
"""

!git push -u origin master

"""## Add and commit model file

### Subtask:
Add your model file to the Git repository and create a commit.

**Reasoning**:
Add the generated model file to the staging area and create a commit with a descriptive message.
"""

!git add image_classification_model.joblib
!git commit -m "Add trained image classification model"

"""## Push to GitHub (Retry)

### Subtask:
Attempt to push the committed model file to your GitHub repository again.

**Reasoning**:
Retry pushing the committed changes to your remote GitHub repository after updating the authentication token.
"""

!git push -u origin master



#!/bin/bash
!curl -L -o ~/cows-and-buffalo-computer-vision-dataset.zip\
  https://www.kaggle.com/api/v1/datasets/download/raghavdharwal/cows-and-buffalo-computer-vision-dataset
!unzip ~/cows-and-buffalo-computer-vision-dataset.zip -d ~/cows-and-buffalo-computer-vision-dataset

import pandas as pd
import numpy as np
import os
import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

# Save trained model in native Keras format
model.save("cow_buffalo_model.keras")

# Save class names
import json
with open("class_names.json", "w") as f:
    json.dump(train_generator.class_indices, f)

print("✅ Model and class names saved successfully!")

import pandas as pd
import numpy as np
import os
import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the training directory
train_dir = os.path.expanduser('~/cows-and-buffalo-computer-vision-dataset/train')

# Define image size and batch size
img_size = (224, 224)
batch_size = 32

# Create ImageDataGenerator for training with data augmentation and validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2 # Split 20% of the data for validation
)

# Use flow_from_directory to load images from the training directory
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training' # Specify training subset
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation' # Specify validation subset
)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense

# Load the pre-trained MobileNetV2 model, excluding the top classification layer
base_model = MobileNetV2(input_shape=img_size + (3,),
                         include_top=False,
                         weights='imagenet')

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(train_generator.num_classes, activation='softmax')
])

# Print the model summary
model.summary()

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Calculate steps per epoch and validation steps
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Train the model
epochs = 15 # Choose a suitable number of epochs
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

!streamlit run app.py &>/dev/null&

# Save trained model in native Keras format
model.save("cow_buffalo_model.keras")

# Save class names
import json
with open("class_names.json", "w") as f:
    json.dump(train_generator.class_indices, f)

print("✅ Model and class names saved successfully!")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# tensorflow
# Pillow
# numpy
# joblib